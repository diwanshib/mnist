{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST best results\n",
    "Result\tMethod\tVenue\tDetails\n",
    "1. 0.21%\tRegularization of Neural Networks using DropConnect\tICML 2013\t\n",
    "2. 0.23%\tMulti-column Deep Neural Networks for Image ClassiÔ¨Åcation\tCVPR 2012\t\n",
    "3. 0.23%\tAPAC: Augmented PAttern Classification with Neural Networks\tarXiv 2015\t\n",
    "4. 0.24%\tBatch-normalized Maxout Network in Network\tarXiv 2015\tDetails\n",
    "5. 0.29%\tGeneralizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree\tAISTATS 2016\tDetails\n",
    "6. 0.31%\tRecurrent Convolutional Neural Network for Object Recognition\tCVPR 2015\t\n",
    "\n",
    "http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 1070 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Lambda, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam as Adam\n",
    "\n",
    "# try leaky relu\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = 28\n",
    "cols = 28\n",
    "\n",
    "# theano input shape\n",
    "input_shape = (1, rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vgg expects channels - here we have just one\n",
    "x_train = x_train.reshape(x_train.shape[0], 1, 28, 28)\n",
    "x_test = x_test.reshape(x_test.shape[0], 1, 28, 28)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to float\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "# normalize\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels should be onehot encoded\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate mean and standard deviation\n",
    "mean_px = x_train.mean().astype(np.float32)\n",
    "std_px = x_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to normalize input data\n",
    "def norm_input(x): return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jeremy's model, inspired by vgg16\n",
    "# Batchnorm + dropout + data augmentation\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        BatchNormalization(input_shape=(1,28,28)),\n",
    "        Conv2D(32, (3,3)),\n",
    "        LeakyReLU(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, (3,3)),\n",
    "        LeakyReLU(),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3)),\n",
    "        LeakyReLU(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3)),\n",
    "        LeakyReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512),\n",
    "        LeakyReLU(),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "Use keras's data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=12, width_shift_range=0.1, shear_range=0.3,\n",
    "                        height_shift_range=0.1, zoom_range=0.1, data_format='channels_first')\n",
    "batches = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    "test_batches = gen.flow(x_test, y_test, batch_size=batch_size)\n",
    "steps_per_epoch = int(np.ceil(batches.n/batch_size))\n",
    "validation_steps = int(np.ceil(test_batches.n/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f26c95eb160>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+5Ke6Lp0ZxEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f26cb715390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load ONE image from training set to display on screen\n",
    "img = x_train[1]\n",
    "\n",
    "# visualize original image\n",
    "plt.imshow(img[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trick our generator into believing img has enough dimensions\n",
    "# and get some augmented images for our single test image\n",
    "img = np.expand_dims(img, axis=0)\n",
    "aug_iter = gen.flow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_img = next(aug_iter)[0].astype(np.float32)\n",
    "aug_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAABqCAYAAABZAFxNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f26c9631390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show augmented images\n",
    "f = plt.figure(figsize=(12,6))\n",
    "for i in range(8):\n",
    "    sp = f.add_subplot(2, 26//3, i+1)\n",
    "    sp.axis('Off')\n",
    "    aug_img = next(aug_iter)[0].astype(np.float32)\n",
    "    plt.imshow(aug_img[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "# Only required if featurewise_center or featurewise_std_normalization or zca_whitening.\n",
    "# gen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models with pretrained weights\n",
    "Here we build on previously trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load weights for existing models and train them some more\n",
    "# this will hopefully result in a better prediction accuracy\n",
    "models = []\n",
    "for i in range(10):\n",
    "    m = create_model()\n",
    "    m.load_weights(\"weights_leaky_relu-batchnorm_input_0.3_\"+str(i)+'.pkl')    \n",
    "    models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0285 - acc: 0.9909 - val_loss: 0.0238 - val_acc: 0.9911\n",
      "Model 1\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0343 - acc: 0.9889 - val_loss: 0.0282 - val_acc: 0.9914\n",
      "Model 2\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0276 - acc: 0.9918 - val_loss: 0.0299 - val_acc: 0.9909\n",
      "Model 3\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0290 - acc: 0.9906 - val_loss: 0.0237 - val_acc: 0.9917\n",
      "Model 4\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0302 - acc: 0.9903 - val_loss: 0.0256 - val_acc: 0.9916\n",
      "Model 5\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0309 - acc: 0.9904 - val_loss: 0.0249 - val_acc: 0.9919\n",
      "Model 6\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0298 - acc: 0.9903 - val_loss: 0.0266 - val_acc: 0.9921\n",
      "Model 7\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0289 - acc: 0.9907 - val_loss: 0.0246 - val_acc: 0.9924\n",
      "Model 8\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0312 - acc: 0.9905 - val_loss: 0.0267 - val_acc: 0.9903\n",
      "Model 9\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0307 - acc: 0.9899 - val_loss: 0.0269 - val_acc: 0.9911\n"
     ]
    }
   ],
   "source": [
    "# train models some more if accuracy is not satisfying enough\n",
    "for i, m in enumerate(models):\n",
    "    print(\"Model {}\".format(i))\n",
    "    m.optimizer.lr = 0.00001\n",
    "    m.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1,\n",
    "                   validation_data=test_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling\n",
    "Here we create ten models and fit them to our augmented data. We use the mean prediction from all ten classifiers as our final prediction. This should average out errors in our classifiers and enable us to predict with higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the model on batches with real-time data augmentation\n",
    "def fit_model(m):\n",
    "    m.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1, verbose=0,\n",
    "                   validation_data=test_batches, validation_steps=validation_steps)\n",
    "    m.optimizer.lr = 0.1\n",
    "    m.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=4, verbose=0,\n",
    "                   validation_data=test_batches, validation_steps=validation_steps)\n",
    "    m.optimizer.lr = 0.01\n",
    "    m.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=6, verbose=0,\n",
    "                   validation_data=test_batches, validation_steps=validation_steps)\n",
    "    m.optimizer.lr = 0.001\n",
    "    m.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=10, verbose=0,\n",
    "                   validation_data=test_batches, validation_steps=validation_steps)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train ten models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0\n",
      "Training model 1\n",
      "Training model 2\n",
      "Training model 3\n",
      "Training model 4\n",
      "Training model 5\n",
      "Training model 6\n",
      "Training model 7\n",
      "Training model 8\n",
      "Training model 9\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"Training model {}\".format(i))\n",
    "    m = fit_model(create_model())\n",
    "    models.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 12s - loss: 0.0241 - acc: 0.9923 - val_loss: 0.0216 - val_acc: 0.9929\n",
      "Model 1\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0252 - acc: 0.9922 - val_loss: 0.0242 - val_acc: 0.9925\n",
      "Model 2\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 12s - loss: 0.0252 - acc: 0.9923 - val_loss: 0.0249 - val_acc: 0.9918\n",
      "Model 3\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0248 - acc: 0.9920 - val_loss: 0.0248 - val_acc: 0.9919\n",
      "Model 4\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 12s - loss: 0.0249 - acc: 0.9925 - val_loss: 0.0234 - val_acc: 0.9918\n",
      "Model 5\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0259 - acc: 0.9920 - val_loss: 0.0216 - val_acc: 0.9932\n",
      "Model 6\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0225 - acc: 0.9929 - val_loss: 0.0234 - val_acc: 0.9918\n",
      "Model 7\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0233 - acc: 0.9924 - val_loss: 0.0273 - val_acc: 0.9908\n",
      "Model 8\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0239 - acc: 0.9925 - val_loss: 0.0238 - val_acc: 0.9932\n",
      "Model 9\n",
      "Epoch 1/1\n",
      "118/118 [==============================] - 11s - loss: 0.0252 - acc: 0.9920 - val_loss: 0.0240 - val_acc: 0.9920\n"
     ]
    }
   ],
   "source": [
    "# train models some more if accuracy is not satisfying enough\n",
    "for i, m in enumerate(models):\n",
    "    m.optimizer.lr = 0.001\n",
    "    print(\"Model {}\".format(i))\n",
    "    m.fit_generator(batches, steps_per_epoch=steps_per_epoch, epochs=1,\n",
    "                   validation_data=test_batches, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9216/10000 [==========================>...] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# evaluate every model\n",
    "evals = np.array([m.evaluate(x_test,y_test, batch_size=eval_batch_size) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01151516,  0.99645   ])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean from evaluations\n",
    "evals.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_preds = np.stack([m.predict(x_test, batch_size=eval_batch_size) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10000, 10)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds = all_preds.mean(axis=0)\n",
    "avg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23999810218811035"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display error rate in percent\n",
    "(1 - keras.metrics.categorical_accuracy(y_test, avg_preds).eval().mean()) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Activation \"relu\":\n",
    "1. 0.26999711990356445\n",
    "2. 0.26000142097473145 trained for one additional epoch\n",
    "\n",
    "Activation \"leaky relu\":\n",
    "1. 0.34000277519226074\n",
    "2. 0.23999810218811035 + two epochs with lr 0.0001 (saved weights as _24)\n",
    "3. 0.23000240325927734 + two epochs with lr 0.0001 (saved weights as _23)\n",
    "\n",
    "with bachnormalization input layer\n",
    "1. 0.3899991512298584\n",
    "2. 0.31999945640563965 +2 ep 0.0001\n",
    "3. 0.3099977970123291 +2 ep 0.0001\n",
    "4. 0.30000209808349609 +2ep 0.001\n",
    "5. 0.26000142097473145 +2ep 0.001\n",
    "6. 0.23999810218811035 +2ep 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try evaluation only with best performing models\n",
    "This doesn't seem to improve results at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_numbers = [0,1,2,3,4,5,7,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_models = []\n",
    "\n",
    "for i in best_model_numbers:\n",
    "    best_models.append(models[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9728/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# evaluate every model\n",
    "evals = np.array([m.evaluate(x_test,y_test, batch_size=eval_batch_size) for m in best_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01328905,  0.9958125 ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean from evaluations\n",
    "evals.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-4133141a911b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_batch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_models\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_models' is not defined"
     ]
    }
   ],
   "source": [
    "all_preds = np.stack([m.predict(x_test, batch_size=eval_batch_size) for m in best_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10000, 10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds = all_preds.mean(axis=0)\n",
    "avg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26000142097473145"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display error rate in percent\n",
    "(1 - keras.metrics.categorical_accuracy(y_test, avg_preds).eval().mean()) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fix for python3\n",
    "import pydotplus as pydot\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(models[0], to_file='model.png')\n",
    "\n",
    "# visualize our model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(models[0]).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights if model is accurate enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the weights for every classifier\n",
    "for i, m in enumerate(models):\n",
    "    m.save_weights(\"weights_leaky_relu-batchnorm_input_0.24_\"+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
